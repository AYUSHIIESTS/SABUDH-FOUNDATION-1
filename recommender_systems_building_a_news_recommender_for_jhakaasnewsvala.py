# -*- coding: utf-8 -*-
"""Recommender Systems: Building a News Recommender for JhakaasNewsVala.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sObEbpME3FpfKPTahotSM9e-bUZiW3m6
"""

# Required Libraries
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import normalize
from sklearn.multioutput import MultiOutputRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import random

# Step 1: Data Preparation
def preprocess_articles(articles):
    # Combine content and title for TF-IDF
    articles['combined_content'] = articles['title'] + ' ' + articles['content']

    # TF-IDF Vectorization
    vectorizer = TfidfVectorizer(stop_words='english', max_features=300)
    tfidf_matrix = vectorizer.fit_transform(articles['combined_content'])

    # Clustering articles based on content
    kmeans = KMeans(n_clusters=5, random_state=42)
    article_clusters = kmeans.fit_predict(tfidf_matrix)
    articles['cluster'] = article_clusters

    return articles, tfidf_matrix

# Sample Data - articles
articles = [
    {"id": 1, "title": "Innovative Tech Trends for 2025", "content": "Exploring AI advancements, Blockchain evolution, and the future of Cloud Computing.", "category": "Technology"},
    {"id": 2, "title": "Highlights of Sports Championships 2024", "content": "An overview of major events including the Olympics, FIFA World Cup, and key local leagues.", "category": "Sports"},
    {"id": 3, "title": "Breakthroughs in Space Exploration", "content": "Updates on Mars missions, satellite technologies, and the role of leading space agencies.", "category": "Science"},
    {"id": 4, "title": "Insights into Financial Markets", "content": "Analysis of stock market trends, cryptocurrency developments, and global economic forecasts.", "category": "Finance"},
    {"id": 5, "title": "The Impact of Global Warming", "content": "Assessing climate change effects and their environmental impact on our planet.", "category": "Environment"},
    {"id": 6, "title": "Health Innovations in 2024", "content": "Breakthroughs in medical technology and their implications for global health.", "category": "Health"},
    {"id": 7, "title": "Cultural Shifts and Trends", "content": "Examining significant cultural changes and their influence on society.", "category": "Culture"},
    {"id": 8, "title": "Advancements in Renewable Energy", "content": "Progress in solar, wind, and other renewable energy sources.", "category": "Energy"},
    {"id": 9, "title": "Urban Development and Smart Cities", "content": "Innovative approaches to urban planning and the development of smart cities.", "category": "Urban Development"},
    {"id": 10, "title": "Educational Reforms and Future Learning", "content": "Exploring changes in educational systems and the future of learning.", "category": "Education"},
    # Add more articles as needed
]
articles_df = pd.DataFrame(articles)

# Preprocess articles
articles_df, tfidf_matrix = preprocess_articles(articles_df)

# Step 2: Recommender System - Multi-Armed Bandit Algorithm
class MultiArmedBandit:
    def __init__(self, n_arms):
        self.n_arms = n_arms
        self.q_values = np.zeros(n_arms)  # estimated values
        self.n_selected = np.zeros(n_arms)  # times each arm is selected
        self.alpha = 0.1  # learning rate

    def select_arm(self):
        # Implement epsilon-greedy strategy to balance exploration and exploitation
        epsilon = 0.1  # Exploration rate
        if random.random() < epsilon:
            return random.randint(0, self.n_arms - 1)  # explore
        else:
            return np.argmax(self.q_values)  # exploit: choose the arm with highest value

    def update(self, chosen_arm, reward):
        self.n_selected[chosen_arm] += 1
        self.q_values[chosen_arm] += self.alpha * (reward - self.q_values[chosen_arm])

# Step 3: Dynamic User Profiling
def build_user_profile(user_id, clicks, articles_df):
    user_clicks = clicks[clicks['user_id'] == user_id]
    cluster_counts = user_clicks.groupby('cluster').size()
    user_profile = articles_df.iloc[cluster_counts.index]['category'].value_counts(normalize=True)
    return user_profile

# Example of building a user profile for a user
user_clicks = [
    {"user_id": 1, "article_id": 1, "timestamp": 1},
    {"user_id": 1, "article_id": 3, "timestamp": 2},
]
user_clicks_df = pd.DataFrame(user_clicks)

user_profile = build_user_profile(user_id=1, clicks=user_clicks_df, articles_df=articles_df)
print("User Profile:", user_profile)

# Step 4: Bias Mitigation
def mitigate_bias(articles_df):
    article_positions = range(1, len(articles_df) + 1)
    click_rates = articles_df.groupby('id').size() / article_positions
    articles_df['adjusted_ctr'] = click_rates / len(articles_df)
    return articles_df

# Apply bias mitigation
articles_df = mitigate_bias(articles_df)

# Step 5: Implementing Recommendations
def recommend_articles(user_id, articles_df, bandit, user_profiles):
    # Handle cold start problem
    if user_id not in user_profiles:
        # Recommend popular articles if user has no interaction history
        return articles_df.sample(5)['id']

    # Get user profile
    user_profile = user_profiles.get(user_id, None)

    # Explore-Exploit strategy
    arm = bandit.select_arm()
    cluster = articles_df.iloc[arm]['cluster']
    recommended_articles = articles_df[articles_df['cluster'] == cluster].sample(5)['id']
    return recommended_articles

# Instantiate multi-armed bandit
bandit = MultiArmedBandit(n_arms=len(articles_df))

# Example recommendation for a user
recommended_articles = recommend_articles(user_id=1, articles_df=articles_df, bandit=bandit, user_profiles={1: user_profile})
print("Recommended Articles for User 1:", recommended_articles)

# Step 6: Coverage Maximization via Diverse Recommendations
def cluster_articles(articles, n_clusters):
    vectorizer = TfidfVectorizer(stop_words='english', max_features=300)
    tfidf_matrix = vectorizer.fit_transform(articles['combined_content'])
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(tfidf_matrix)
    articles['cluster'] = cluster_labels
    return articles

# Applying clustering for diversity
articles_df = cluster_articles(articles_df, n_clusters=5)

# Step 7: Evaluating Recommendation Quality
def evaluate_ctr(recommended, actual):
    return sum(recommended == actual) / len(actual)

# Sample evaluation
actual_clicks = [1, 3]  # user clicked on these articles
recommended = [1, 2, 3, 4, 5]  # articles recommended to the user
ctr = evaluate_ctr(recommended, actual_clicks)
print("CTR:", ctr)

# Step 8: Expanding Recommendation Strategies
def expand_recommendation_strategies(user_id, articles_df, bandit, user_profiles):
    # Use content-based filtering for similar user groups
    if user_id in user_profiles:
        similar_users = find_similar_users(user_id, user_profiles)
        similar_articles = set()
        for user in similar_users:
            similar_articles.update(recommend_articles(user, articles_df, bandit, user_profiles))
        return list(similar_articles)[:5]
    else:
        # If no similar users, recommend popular articles
        return recommend_articles(user_id, articles_df, bandit, user_profiles)

def find_similar_users(user_id, user_profiles):
    # Implement a similarity metric (e.g., cosine similarity) to find similar users
    user_vector = user_profiles[user_id]
    similarities = {}
    for other_user in user_profiles:
        if other_user != user_id:
            similarity = cosine_similarity([user_vector], [user_profiles[other_user]])[0][0]
            similarities[other_user] = similarity
    # Select top 5 similar users
    similar_users = sorted(similarities, key=similarities.get, reverse=True)[:5]
    return similar_users

# Example of expanding recommendation for a user
expanded_recommendations = expand_recommendation_strategies(user_id=1, articles_df=articles_df, bandit=bandit, user_profiles={1: user_profile})
print("Expanded Recommendations for User 1:", expanded_recommendations)